{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.4'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pymysql\n",
    "from cryptography.fernet import Fernet\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine \n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report as cr\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.features import FeatureImportances\n",
    "\n",
    "%matplotlib inline\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase the size of the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "\"No such keys(s): 'display.height'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-15a15b8aff4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Pandas v0.23.4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.height'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/MusicMood/lib/python3.6/site-packages/pandas/core/config.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/MusicMood/lib/python3.6/site-packages/pandas/core/config.py\u001b[0m in \u001b[0;36m_set_option\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_single_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_registered_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/MusicMood/lib/python3.6/site-packages/pandas/core/config.py\u001b[0m in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0m_warn_if_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOptionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such keys(s): {pat!r}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mOptionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pattern matched multiple keys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOptionError\u001b[0m: \"No such keys(s): 'display.height'\""
     ]
    }
   ],
   "source": [
    "# Pandas v0.23.4\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decrypt Credentials and Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncode the secret license file\n",
    "def unencrypt():\n",
    "    try:\n",
    "        key = b'IXx5rHfP15FqP4ahx2pwcud-XmcBzU553Ri6p-nVhnc=' #Fernet.generate_key()\n",
    "        cipher_suite = Fernet(key)\n",
    "        with open('/usr/local/etc/musicmood_bytes.bin', 'rb') as file_object:\n",
    "            for line in file_object:\n",
    "                encryptedpwd = line\n",
    "        uncipher_text = (cipher_suite.decrypt(encryptedpwd))\n",
    "        plain_text_encryptedpassword = bytes(uncipher_text).decode(\"utf-8\") #convert to string\n",
    "        x = json.loads(plain_text_encryptedpassword, object_hook=lambda d: namedtuple('X', d.keys())(*d.values()))\n",
    "        return x\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return \"Error\" \n",
    "\n",
    "#Setup the database connection\n",
    "credentials = unencrypt()\n",
    "user_id = credentials.user\n",
    "user_password = credentials.password\n",
    "dbname = credentials.dbname\n",
    "server = credentials.server\n",
    "conn = pymysql.connect(server,user_id,user_password,dbname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.498795986175537 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_popularity</th>\n",
       "      <th>weeks_ranked</th>\n",
       "      <th>highest_rank</th>\n",
       "      <th>lowest_rank</th>\n",
       "      <th>weeks_top_spot</th>\n",
       "      <th>weeks_top_10</th>\n",
       "      <th>weeks_top_20</th>\n",
       "      <th>weeks_top_30</th>\n",
       "      <th>weeks_top_40</th>\n",
       "      <th>weeks_top_50</th>\n",
       "      <th>...</th>\n",
       "      <th>gnr_Metal</th>\n",
       "      <th>gnr_Pop</th>\n",
       "      <th>gnr_Pop Standards</th>\n",
       "      <th>gnr_Punk</th>\n",
       "      <th>gnr_Rap Hip Hop</th>\n",
       "      <th>gnr_Rhythm and Blues</th>\n",
       "      <th>gnr_Rock</th>\n",
       "      <th>gnr_Rock and Roll</th>\n",
       "      <th>gnr_Ska Reggae Dancehall</th>\n",
       "      <th>is_top40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "      <td>12255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>461.917585</td>\n",
       "      <td>8.590371</td>\n",
       "      <td>24.106161</td>\n",
       "      <td>57.427989</td>\n",
       "      <td>0.112444</td>\n",
       "      <td>1.080294</td>\n",
       "      <td>2.104774</td>\n",
       "      <td>3.076295</td>\n",
       "      <td>3.985149</td>\n",
       "      <td>4.848960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067156</td>\n",
       "      <td>0.137087</td>\n",
       "      <td>0.019502</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.045777</td>\n",
       "      <td>0.049857</td>\n",
       "      <td>0.368666</td>\n",
       "      <td>0.031089</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>0.379111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>646.707813</td>\n",
       "      <td>9.515133</td>\n",
       "      <td>29.813271</td>\n",
       "      <td>43.503135</td>\n",
       "      <td>1.002081</td>\n",
       "      <td>3.229548</td>\n",
       "      <td>4.882840</td>\n",
       "      <td>6.084759</td>\n",
       "      <td>7.014856</td>\n",
       "      <td>7.747965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250303</td>\n",
       "      <td>0.343953</td>\n",
       "      <td>0.138288</td>\n",
       "      <td>0.047747</td>\n",
       "      <td>0.209010</td>\n",
       "      <td>0.217659</td>\n",
       "      <td>0.482463</td>\n",
       "      <td>0.173566</td>\n",
       "      <td>0.053367</td>\n",
       "      <td>0.485185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>167.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>799.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9009.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bill_popularity  weeks_ranked  highest_rank   lowest_rank  \\\n",
       "count     12255.000000  12255.000000  12255.000000  12255.000000   \n",
       "mean        461.917585      8.590371     24.106161     57.427989   \n",
       "std         646.707813      9.515133     29.813271     43.503135   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      0.000000   \n",
       "50%         167.000000      7.000000      9.000000     82.000000   \n",
       "75%         799.000000     15.000000     44.000000     95.000000   \n",
       "max        9009.000000    104.000000    100.000000    100.000000   \n",
       "\n",
       "       weeks_top_spot  weeks_top_10  weeks_top_20  weeks_top_30  weeks_top_40  \\\n",
       "count    12255.000000  12255.000000  12255.000000  12255.000000  12255.000000   \n",
       "mean         0.112444      1.080294      2.104774      3.076295      3.985149   \n",
       "std          1.002081      3.229548      4.882840      6.084759      7.014856   \n",
       "min          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%          0.000000      0.000000      1.000000      5.000000      7.000000   \n",
       "max         84.000000     88.000000     95.000000     96.000000    104.000000   \n",
       "\n",
       "       weeks_top_50      ...          gnr_Metal       gnr_Pop  \\\n",
       "count  12255.000000      ...       12255.000000  12255.000000   \n",
       "mean       4.848960      ...           0.067156      0.137087   \n",
       "std        7.747965      ...           0.250303      0.343953   \n",
       "min        0.000000      ...           0.000000      0.000000   \n",
       "25%        0.000000      ...           0.000000      0.000000   \n",
       "50%        0.000000      ...           0.000000      0.000000   \n",
       "75%        9.000000      ...           0.000000      0.000000   \n",
       "max      104.000000      ...           1.000000      1.000000   \n",
       "\n",
       "       gnr_Pop Standards      gnr_Punk  gnr_Rap Hip Hop  gnr_Rhythm and Blues  \\\n",
       "count       12255.000000  12255.000000     12255.000000          12255.000000   \n",
       "mean            0.019502      0.002285         0.045777              0.049857   \n",
       "std             0.138288      0.047747         0.209010              0.217659   \n",
       "min             0.000000      0.000000         0.000000              0.000000   \n",
       "25%             0.000000      0.000000         0.000000              0.000000   \n",
       "50%             0.000000      0.000000         0.000000              0.000000   \n",
       "75%             0.000000      0.000000         0.000000              0.000000   \n",
       "max             1.000000      1.000000         1.000000              1.000000   \n",
       "\n",
       "           gnr_Rock  gnr_Rock and Roll  gnr_Ska Reggae Dancehall      is_top40  \n",
       "count  12255.000000       12255.000000              12255.000000  12255.000000  \n",
       "mean       0.368666           0.031089                  0.002856      0.379111  \n",
       "std        0.482463           0.173566                  0.053367      0.485185  \n",
       "min        0.000000           0.000000                  0.000000      0.000000  \n",
       "25%        0.000000           0.000000                  0.000000      0.000000  \n",
       "50%        0.000000           0.000000                  0.000000      0.000000  \n",
       "75%        1.000000           0.000000                  0.000000      1.000000  \n",
       "max        1.000000           1.000000                  1.000000      1.000000  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df = pd.read_sql('SELECT * FROM songs_instances_data', con = conn)\n",
    "print('--- %s seconds ---' % (time.time() - start_time))\n",
    "    \n",
    "df.drop(['index'],axis=1, inplace=True)\n",
    "df.head(15)\n",
    "\n",
    "df.describe()\n",
    "#print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize only important features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12255, 33)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = df [['duration', 'key_song', 'loudness', 'mode', 'tempo', 'time_signature', 'words_song_u', 'words_song', \\\n",
    "             'words_song_r', 'words_genre_u', 'words_genre', 'words_genre_r', 'words_second', 'speed_general', \\\n",
    "             'artist_familiarity', 'artist_hotttnesss', 'gnr_Blues', 'gnr_Country', 'gnr_Folk', 'gnr_Funk', \\\n",
    "             'gnr_House Electronic Trance', 'gnr_Jazz', 'gnr_Latin', 'gnr_Metal', 'gnr_Pop', 'gnr_Pop Standards', \\\n",
    "             'gnr_Punk', 'gnr_Rap Hip Hop', 'gnr_Rhythm and Blues', 'gnr_Rock', 'gnr_Rock and Roll', \\\n",
    "             'gnr_Ska Reggae Dancehall', 'is_top40']]\n",
    "songs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameter Tuning Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to be used as a template to aid in the shared process within the team to obtain the best performance hyper-parameters for the long list of algorithm that we are testing in our project.\n",
    "The next cells are going to explain what should be accomplish with each of the algorithms assigned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split-Out validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step divide our dataset in a ramdom 80/20 train/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = songs.values\n",
    "X = array[:,0:-1]\n",
    "Y = array[:,-1] #is_top40\n",
    "    \n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = \\\n",
    "model_selection.train_test_split(X, Y,test_size=validation_size,stratify = Y, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Test options and evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to test the accuracy metric of different the algorithms truing to increase it as high as possible by trying different combinations of hyper-parameters values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell import the libraries corresponding to all the algorithms that are going to be tested "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select one of the algorithms and show its hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are going to show the parameters for the KNeighborsClassifier algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_components': None,\n",
       " 'priors': None,\n",
       " 'shrinkage': None,\n",
       " 'solver': 'svd',\n",
       " 'store_covariance': False,\n",
       " 'tol': 0.0001}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearDiscriminantAnalysis().get_params(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we don't know so well how this algorithms are conceived and whatthis hyper-parameters mean we should use the help method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LinearDiscriminantAnalysis in module sklearn.discriminant_analysis:\n",
      "\n",
      "class LinearDiscriminantAnalysis(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.base.TransformerMixin)\n",
      " |  Linear Discriminant Analysis\n",
      " |  \n",
      " |  A classifier with a linear decision boundary, generated by fitting class\n",
      " |  conditional densities to the data and using Bayes' rule.\n",
      " |  \n",
      " |  The model fits a Gaussian density to each class, assuming that all classes\n",
      " |  share the same covariance matrix.\n",
      " |  \n",
      " |  The fitted model can also be used to reduce the dimensionality of the input\n",
      " |  by projecting it to the most discriminative directions.\n",
      " |  \n",
      " |  .. versionadded:: 0.17\n",
      " |     *LinearDiscriminantAnalysis*.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <lda_qda>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  solver : string, optional\n",
      " |      Solver to use, possible values:\n",
      " |        - 'svd': Singular value decomposition (default).\n",
      " |          Does not compute the covariance matrix, therefore this solver is\n",
      " |          recommended for data with a large number of features.\n",
      " |        - 'lsqr': Least squares solution, can be combined with shrinkage.\n",
      " |        - 'eigen': Eigenvalue decomposition, can be combined with shrinkage.\n",
      " |  \n",
      " |  shrinkage : string or float, optional\n",
      " |      Shrinkage parameter, possible values:\n",
      " |        - None: no shrinkage (default).\n",
      " |        - 'auto': automatic shrinkage using the Ledoit-Wolf lemma.\n",
      " |        - float between 0 and 1: fixed shrinkage parameter.\n",
      " |  \n",
      " |      Note that shrinkage works only with 'lsqr' and 'eigen' solvers.\n",
      " |  \n",
      " |  priors : array, optional, shape (n_classes,)\n",
      " |      Class priors.\n",
      " |  \n",
      " |  n_components : int, optional\n",
      " |      Number of components (< n_classes - 1) for dimensionality reduction.\n",
      " |  \n",
      " |  store_covariance : bool, optional\n",
      " |      Additionally compute class covariance matrix (default False), used\n",
      " |      only in 'svd' solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |  \n",
      " |  tol : float, optional, (default 1.0e-4)\n",
      " |      Threshold used for rank estimation in SVD solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array, shape (n_features,) or (n_classes, n_features)\n",
      " |      Weight vector(s).\n",
      " |  \n",
      " |  intercept_ : array, shape (n_features,)\n",
      " |      Intercept term.\n",
      " |  \n",
      " |  covariance_ : array-like, shape (n_features, n_features)\n",
      " |      Covariance matrix (shared by all classes).\n",
      " |  \n",
      " |  explained_variance_ratio_ : array, shape (n_components,)\n",
      " |      Percentage of variance explained by each of the selected components.\n",
      " |      If ``n_components`` is not set then all components are stored and the\n",
      " |      sum of explained variances is equal to 1.0. Only available when eigen\n",
      " |      or svd solver is used.\n",
      " |  \n",
      " |  means_ : array-like, shape (n_classes, n_features)\n",
      " |      Class means.\n",
      " |  \n",
      " |  priors_ : array-like, shape (n_classes,)\n",
      " |      Class priors (sum to 1).\n",
      " |  \n",
      " |  scalings_ : array-like, shape (rank, n_classes - 1)\n",
      " |      Scaling of the features in the space spanned by the class centroids.\n",
      " |  \n",
      " |  xbar_ : array-like, shape (n_features,)\n",
      " |      Overall mean.\n",
      " |  \n",
      " |  classes_ : array-like, shape (n_classes,)\n",
      " |      Unique class labels.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis: Quadratic\n",
      " |      Discriminant Analysis\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default solver is 'svd'. It can perform both classification and\n",
      " |  transform, and it does not rely on the calculation of the covariance\n",
      " |  matrix. This can be an advantage in situations where the number of features\n",
      " |  is large. However, the 'svd' solver cannot be used with shrinkage.\n",
      " |  \n",
      " |  The 'lsqr' solver is an efficient algorithm that only works for\n",
      " |  classification. It supports shrinkage.\n",
      " |  \n",
      " |  The 'eigen' solver is based on the optimization of the between class\n",
      " |  scatter to within class scatter ratio. It can be used for both\n",
      " |  classification and transform, and it supports shrinkage. However, the\n",
      " |  'eigen' solver needs to compute the covariance matrix, so it might not be\n",
      " |  suitable for situations with a high number of features.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
      " |  >>> y = np.array([1, 1, 1, 2, 2, 2])\n",
      " |  >>> clf = LinearDiscriminantAnalysis()\n",
      " |  >>> clf.fit(X, y)\n",
      " |  LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      " |                solver='svd', store_covariance=False, tol=0.0001)\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearDiscriminantAnalysis\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model.base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, solver='svd', shrinkage=None, priors=None, n_components=None, store_covariance=False, tol=0.0001)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit LinearDiscriminantAnalysis model according to the given\n",
      " |         training data and parameters.\n",
      " |      \n",
      " |         .. versionchanged:: 0.19\n",
      " |            *store_covariance* has been moved to main constructor.\n",
      " |      \n",
      " |         .. versionchanged:: 0.19\n",
      " |            *tol* has been moved to main constructor.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : array, shape (n_samples,)\n",
      " |          Target values.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Estimate log probability.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples, n_classes)\n",
      " |          Estimated log probabilities.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Estimate probability.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples, n_classes)\n",
      " |          Estimated probabilities.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Project data to maximize class separation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : array, shape (n_samples, n_components)\n",
      " |          Transformed data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LinearDiscriminantAnalysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hyper-Parameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the best ways to find a suitable bet performing set of hyper-parameters for a classifier algorithm is by using GridSearchCV. What you have to do is complete the structure <b>tuned_parameters</b> with possible combinations of values and then run. The process will get you the best combination of parameters for the data. We recommend iterate this process at least 3 times per algorithm changing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper-parameters (Tunning) for accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results ---\n",
      "\n",
      "{'n_components': 0, 'solver': 'svd', 'store_covariance': True, 'tol': 0.0001}\n",
      "\n",
      "Grid scores:\n",
      "\n",
      "0.671 (+/-0.017) for {'n_components': 0, 'solver': 'svd', 'store_covariance': True, 'tol': 0.0001}\n",
      "0.671 (+/-0.017) for {'n_components': 0, 'solver': 'lsqr', 'store_covariance': True, 'tol': 0.0001}\n",
      "0.671 (+/-0.017) for {'n_components': 0, 'solver': 'svd', 'store_covariance': True, 'tol': 0.0001}\n",
      "0.671 (+/-0.017) for {'n_components': 0, 'solver': 'lsqr', 'store_covariance': True, 'tol': 0.0001}\n",
      "0.671 (+/-0.017) for {'n_components': 0, 'solver': 'svd', 'store_covariance': True, 'tol': 0.0001}\n",
      "0.671 (+/-0.017) for {'n_components': 0, 'solver': 'lsqr', 'store_covariance': True, 'tol': 0.0001}\n",
      "\n",
      "Classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.81      0.76      1522\n",
      "        1.0       0.59      0.45      0.51       929\n",
      "\n",
      "avg / total       0.66      0.67      0.66      2451\n",
      "\n",
      "\n",
      "--- 0.5863611698150635 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "LinearDiscriminantAnalysis().get_params(deep = True)\n",
    "\n",
    "\n",
    "tuned_parameters = [{\n",
    "                        'n_components': [0], \n",
    "                        'solver': ['svd','lsqr'],\n",
    "                        'store_covariance': [True],\n",
    "                        'tol': [0.0001]\n",
    "                     },\n",
    "                     {\n",
    "                        'n_components': [0], \n",
    "                        'solver': ['svd','lsqr'],\n",
    "                        'store_covariance': [True],\n",
    "                        'tol': [0.0001]\n",
    "                     },\n",
    "                     {\n",
    "                        'n_components': [0], \n",
    "                        'solver': ['svd','lsqr'],\n",
    "                        'store_covariance': [True],\n",
    "                        'tol': [0.0001]\n",
    "                     }\n",
    "                    ]\n",
    "\n",
    "#scores = ['precision', 'recall']\n",
    "scores = ['accuracy']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"Hyper-parameters (Tunning) for %s\" % score)\n",
    "    print()\n",
    "    start_time = time.time()\n",
    "    clf = GridSearchCV(LinearDiscriminantAnalysis(), tuned_parameters, cv=5, scoring=score)\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    print()\n",
    "    print(\"--- Results ---\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "    \n",
    "print(\"Classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = Y_validation, clf.predict(X_validation)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "print('--- %s seconds ---' % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Analyze and Store the best set of parameters for the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "0.6744186046511628\n",
      "[[1235  287]\n",
      " [ 511  418]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/MusicMood/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#{'algorithm': 'ball_tree', 'leaf_size': 20, 'metric': 'minkowski', 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n",
    "model = LinearDiscriminantAnalysis(n_components= 0, solver= 'svd', store_covariance= True, tol= 0.0001)\n",
    "\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "classes = [\"IsTop40\", \"NoHit\"]\n",
    "def plotting(name, model):\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_validation)\n",
    "    print(name)\n",
    "    print(accuracy_score(Y_validation, predictions))\n",
    "    print(confusion_matrix(Y_validation, predictions))\n",
    "    visualizer = ClassificationReport(model, classes=classes, support=True)\n",
    "    visualizer.fit(X_train, Y_train)  # Fit the visualizer and the model\n",
    "    visualizer.score(X_validation, Y_validation)  # Evaluate the model on the test data\n",
    "    g = visualizer.poof()             # Draw/show/poof the data\n",
    "    \n",
    "\n",
    "plotting(\"KNeighborsClassifier\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Submit via email the set of best parameters for the algorithms you were assigned "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.62\t(+/-0.017)\tfor\t{'algorithm':\t'ball_tree',\t'leaf_size':\t20,\t'metric':\t'minkowski',\t'n_neighbors':\t7,\t'p':\t2,\t'weights':\t'uniform'}\n",
    "0.62\t(+/-0.017)\tfor\t{'algorithm':\t'ball_tree',\t'leaf_size':\t30,\t'metric':\t'minkowski',\t'n_neighbors':\t7,\t'p':\t2,\t'weights':\t'uniform'}\n",
    "0.62\t(+/-0.017)\tfor\t{'algorithm':\t'ball_tree',\t'leaf_size':\t40,\t'metric':\t'minkowski',\t'n_neighbors':\t7,\t'p':\t2,\t'weights':\t'uniform'}\n",
    "0.62\t(+/-0.017)\tfor\t{'algorithm':\t'kd_tree',\t'leaf_size':\t20,\t'metric':\t'minkowski',\t'n_neighbors':\t7,\t'p':\t2,\t'weights':\t'uniform'}\n",
    "0.62\t(+/-0.017)\tfor\t{'algorithm':\t'kd_tree',\t'leaf_size':\t30,\t'metric':\t'minkowski',\t'n_neighbors':\t7,\t'p':\t2,\t'weights':\t'uniform'}\n",
    "0.62\t(+/-0.017)\tfor\t{'algorithm':\t'kd_tree',\t'leaf_size':\t40,\t'metric':\t'minkowski',\t'n_neighbors':\t7,\t'p':\t2,\t'weights':\t'uniform'}\n",
    "0.62\t(+/-0.017)\tfor\t{'algorithm':\t'brute',\t'leaf_size':\t20,\t'metric':\t'minkowski',\t'n_neighbors':\t7,\t'p':\t2,\t'weights':\t'uniform'}\n",
    "0.62\t(+/-0.017)\tfor\t{'algorithm':\t'brute',\t'leaf_size':\t30,\t'metric':\t'minkowski',\t'n_neighbors':\t7,\t'p':\t2,\t'weights':\t'uniform'}\n",
    "0.62\t(+/-0.017)\tfor\t{'algorithm':\t'brute',\t'leaf_size':\t40,\t'metric':\t'minkowski',\t'n_neighbors':\t7,\t'p':\t2,\t'weights':\t'uniform'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
